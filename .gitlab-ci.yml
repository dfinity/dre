default:
  image: registry.gitlab.com/dfinity-lab/core/release/ci-build@sha256:c8cf6b5619310715133557064e194ff748133e470224154473ac84d190a8b22d
  tags:
    # Use the Dfinity CI runners (they have following tags)
    - dfinity
    - docker
    - ubuntu
  # Retry config copied from:
  # https://gitlab.com/gitlab-org/gitlab/blob/master/.gitlab/ci/global.gitlab-ci.yml#L1-9
  # Complete description available at:
  # https://docs.gitlab.com/ee/ci/yaml/#retry
  retry:
    max: 2  # This is confusing but this means "3 runs at max".
    when:
      - unknown_failure
      - api_failure
      - runner_system_failure

stages:
  - release
  - test

variables:
  GET_SOURCES_ATTEMPTS: 5
  GIT_DEPTH: 0  # Pull the complete repo initially
  GIT_STRATEGY: "fetch"  # And then pull only new commits
  CI_PRE_CLONE_SCRIPT: |
    # This script prepares the docker container for running the job
    # The most important thing done here is pre-seeding the repo in the $CI_PROJECT_DIR so that
    # the docker gitlab runner doesn't have to re-clone the repo for every job
    # Example of the (official gitlab) CI_PRE_CLONE_SCRIPT:
    # https://docs.gitlab.com/ee/development/pipelines.html#pre-clone-step
    # MacOS note: the gitlab runner will ignore this var on MacOS since config does not have
    # pre_clone_script set in the runner config

    set -eExuo pipefail
    echo -e "\e[0Ksection_start:@(date +%s):pre_clone_script[collapsed=true]\r\e[0KClick here to see the pre_clone_script section"

    # Fail the git clone/pull if too slow
    export GIT_HTTP_LOW_SPEED_LIMIT=10000 GIT_HTTP_LOW_SPEED_TIME=10 GIT_SSH_COMMAND='timeout 300 ssh -T'

    # WARNING: We use @ instead of $ because GitLab sometimes silently converts $VAR into VAR
    # WARNING: The @ signs will be replaced with $ before executing the script
    rm -rf "@{CI_PROJECT_DIR}"
    mkdir -p "@{CI_PROJECT_DIR}"
    chown 1000:1000 -R "@{CI_PROJECT_DIR}"
    if [[ -d "/cache/git-v3/@{CI_PROJECT_PATH}/@CI_CONCURRENT_ID" ]]; then
      trap 'rm -rf "/cache/git-v3/@{CI_PROJECT_PATH}/@CI_CONCURRENT_ID"' ERR
      # Concurrent jobs are separated into different git repo cache folders
      echo "Copying the git repo from /cache/git-v3/@{CI_PROJECT_PATH}/@{CI_CONCURRENT_ID} to @{CI_PROJECT_DIR}"
      /usr/bin/time cp -a --no-target-directory "/cache/git-v3/@{CI_PROJECT_PATH}/@CI_CONCURRENT_ID/" "@{CI_PROJECT_DIR}/"

      if [[ -n "@{GIT_CLONE_PATH:-}" && "@{GIT_CLONE_PATH:-}" != "@{CI_PROJECT_DIR}" ]]; then
        # @GIT_CLONE_PATH is set to a value different from @{CI_PROJECT_DIR}
        # In general the two should be the same so this code path should never be exercised
        rm -rf "@GIT_CLONE_PATH"
        mkdir -p "@GIT_CLONE_PATH"
        chown 1000:1000 -R "@GIT_CLONE_PATH"
        /usr/bin/time cp -a --no-target-directory "/cache/git-v3/@{CI_PROJECT_PATH}/@CI_CONCURRENT_ID/" "@GIT_CLONE_PATH/"
      fi


      # Ensure the git repo is clean and up to date with the upstream
      cd "@{CI_PROJECT_DIR}"
      # Disable all background git operations
      git config gc.auto 0
      git config gc.autodetach false

      # Ensure that there are not background git operations running and remove all lock files if they exist
      if ! {
        set -e
        pkill git || true
        find .git -name '*.lock' -delete
        # Delete all branches for which a reference (sha) does not exist
        set +x
        git for-each-ref --format="%(refname)" | while read ref; do
          git show-ref --quiet --verify @ref 2>/dev/null || git update-ref -d @ref
        done
        set -x
        if ! git remote add origin "@{CI_REPOSITORY_URL}"; then
          git remote set-url origin "@{CI_REPOSITORY_URL}"
        fi
        git fetch --prune --prune-tags
        # Run a GC on the repo
        git gc --prune=now --force
        git reflog expire --expire=0 --all
      }; then
        rm -rf .git
      fi
    fi
    echo -e "\e[0Ksection_end:$(date +%s):pre_clone_script\r\e[0K"


before_script:
  - |
    # Execute the before_script section

    # Start the (collapsed) before_script section
    set -eExuo pipefail
    echo -e "\e[0Ksection_start:$(date +%s):before_script[collapsed=true]\r\e[0KClick here to see the before_script section"

    echo -e "Host *\nUser gitlab-runner\n" > ~/.ssh/config
    ulimit -n 8192
    date

    # forget original timestamp/timestamp when compressing ~ important for reproducibility
    export GZIP=-n

    # Set the IC repo URL to https instead of ssh, and check out the submodule
    git submodule set-url ic "https://github.com/dfinity/ic.git"
    if ! git submodule update --init --recursive --remote; then
      cat .git/config
      cat .gitmodules
      cat .git/modules/ic/config
      rm -rf /cache/git-v3/${CI_PROJECT_PATH}
      exit 1
    fi

    sudo chown ubuntu:ubuntu -R "${CI_PROJECT_DIR}"
    sudo find "${CI_PROJECT_DIR}" -type d -exec chmod 0755 '{}' \;
    # Update the git repo cache at /cache/git-v3/${CI_PROJECT_PATH}/$CI_CONCURRENT_ID
    mkdir -p "/cache/git-v3/${CI_PROJECT_PATH}/$CI_CONCURRENT_ID/"
    /usr/bin/time rsync -a --force --delete "$CI_PROJECT_DIR"/ "/cache/git-v3/${CI_PROJECT_PATH}/$CI_CONCURRENT_ID/"

    cd "${CI_PROJECT_DIR}"
    # Ensure file permissions in the repo are what git expects them to be
    git config core.fileMode true
    git reset --hard HEAD

  - echo -e "\e[0Ksection_end:$(date +%s):before_script\r\e[0K"
  # Setup SSH keys
  - 'command -v ssh-agent >/dev/null || ( apt-get update -y && apt-get install openssh-client -y )'
  - eval $(ssh-agent -s)
  - cat "$DASHBOARD_DEPLOY_KEY" | tr -d '\r' | ssh-add -
  - mkdir -p ~/.ssh
  - chmod 700 ~/.ssh

.rules-default:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run

.rules-autorun-on-trigger:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'

docker-image-update:
  stage: .pre
  extends:
    - .rules-default
  interruptible: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - docker/**/*
        - Pipfile
        - Pipfile.lock
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run
  script:
    - python3 docker/docker-update-image.py

pre-commit:
  extends:
    - .rules-default
  interruptible: true
  needs: []
  dependencies: []
  stage: test
  variables:
    PRE_COMMIT_HOME: "/cache/pre-commit/${CI_PROJECT_PATH}/$CI_CONCURRENT_ID"
  script:
    - pre-commit install
    - pre-commit run -a --hook-stage=manual

cargo-clippy:
  extends:
    - .rules-default
  interruptible: true
  needs: []
  dependencies: []
  stage: test
  script:
    - cd rs
    - ./cargo-clippy

cargo-test:
  extends:
    - .rules-default
  interruptible: true
  needs: []
  dependencies: []
  stage: test
  script:
    - cd rs
    - cargo test

update-facts-db:
  interruptible: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "update-factsdb"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run
  script:
    - |
      set -eExou pipefail  # Don't tolerate any errors
      # Work on main branch
      git config pull.rebase true
      git config --global user.name "Release Team"
      git config --global user.email "eng-release-bots-aaaafbmaump5gpag4pbjfuarry@dfinity.slack.com"
      time git pull --depth 5 --force origin "${CI_DEFAULT_BRANCH}"
      git checkout --force "${CI_DEFAULT_BRANCH}"

      set +x
      time python3 ./factsdb/main.py --refresh
      if [[ -n "$(git status --short factsdb/data)" ]]; then
        echo "Changed files found";
        git add factsdb/data
        git stash
        git pull --rebase
        git stash pop
        git add factsdb/data
        git status
        git commit -m"Updated FactsDB"
        git remote set-url origin "https://token:${GITLAB_PUSH_TOKEN}@${CI_REPOSITORY_URL#*@}"
        git push origin "${CI_DEFAULT_BRANCH}"
      fi

jira-update:
  interruptible: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "update-jira-tickets"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run
  script:
    - |
      set -eExou pipefail  # Don't tolerate any errors

      cd ./scripts/jira-integration
      time python3 ./jira_update.py

qualification-tracking-update:
  interruptible: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "update-qualification-tracking"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true  # the pipeline continues running even if the manual job is not run
  script:
    - |
      set -eExou pipefail  # Don't tolerate any errors

      cd ./qualification
      time python3 ./qualification_track.py add-nns
      time python3 ./qualification_track.py add-ci --since=now-3d

dashboard-release:
  image: docker/compose:alpine-1.29.2
  needs: []
  dependencies: []
  stage: release
  retry: 2
  extends:
    - .rules-default
  interruptible: true
  before_script:
    - docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" $CI_REGISTRY
  variables:
    IMAGE_REGISTRY_BASE: $CI_REGISTRY_IMAGE
    RELEASE_BRANCH: release
    COMPOSE_DOCKER_CLI_BUILD: "1"
    DOCKER_BUILDKIT: "1"
  script:
    - cd dashboard
    - TAG=latest docker-compose pull || true
    - TAG=latest docker-compose -f docker-compose.yml -f docker-compose.dev.yml build --parallel
    - if [ "${CI_COMMIT_BRANCH}" != "${CI_DEFAULT_BRANCH}" ]; then exit 0; fi
    - TAG=${CI_COMMIT_SHA} docker-compose -f docker-compose.yml -f docker-compose.dev.yml build --parallel
    - TAG=latest docker-compose -f docker-compose.yml -f docker-compose.dev.yml push
    - TAG=${CI_COMMIT_SHA} docker-compose -f docker-compose.yml -f docker-compose.dev.yml push
    - apk add git && git remote set-url origin "https://token:${GITLAB_PUSH_TOKEN}@${CI_REPOSITORY_URL#*@}"
    - if git fetch origin $RELEASE_BRANCH; then \
        git checkout $RELEASE_BRANCH && git reset --hard ${CI_COMMIT_SHA} && git push --force origin $RELEASE_BRANCH; \
      else \
        git checkout -b $RELEASE_BRANCH && git push --force origin $RELEASE_BRANCH \
      fi
