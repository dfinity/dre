default:
  image: registry.gitlab.com/dfinity-lab/core/release/ci-build@sha256:d0d2195ba8637185d22a1fbb7863e6145a2f0404a3c4a70b20e4e7fd6016dcea
  tags:
    # Use the Dfinity CI runners (they have following tags)
    - dfinity
    - docker
    - ubuntu
  # Retry config copied from:
  # https://gitlab.com/gitlab-org/gitlab/blob/master/.gitlab/ci/global.gitlab-ci.yml#L1-9
  # Complete description available at:
  # https://docs.gitlab.com/ee/ci/yaml/#retry
  retry:
    max: 2 # This is confusing but this means "3 runs at max".
    when:
      - unknown_failure
      - api_failure
      - runner_system_failure

stages:
  - release
  - test

variables:
  QUALIFY_GIT_REVISION:
    description: "Please provide the git revision that should be qualified"
  GET_SOURCES_ATTEMPTS: 5
  GIT_DEPTH: 0 # Pull the complete repo initially
  GIT_STRATEGY: "fetch" # And then pull only new commits
  CI_PRE_CLONE_SCRIPT: |
    # This script prepares the docker container for running the job
    # The most important thing done here is pre-seeding the repo in the $CI_PROJECT_DIR so that
    # the docker gitlab runner doesn't have to re-clone the repo for every job
    # Example of the (official gitlab) CI_PRE_CLONE_SCRIPT:
    # https://docs.gitlab.com/ee/development/pipelines.html#pre-clone-step
    # MacOS note: the gitlab runner will ignore this var on MacOS since config does not have
    # pre_clone_script set in the runner config

    set -exuo pipefail
    echo -e "\e[0Ksection_start:@(date +%s):pre_clone_script[collapsed=true]\r\e[0KClick here to see the pre_clone_script section"

    # Fail the git clone/pull if too slow
    export GIT_HTTP_LOW_SPEED_LIMIT=10000 GIT_HTTP_LOW_SPEED_TIME=10 GIT_SSH_COMMAND='timeout 300 ssh -T'

    # WARNING: We use @ instead of $ because GitLab sometimes silently converts $VAR into VAR
    # WARNING: The @ signs will be replaced with $ before executing the script
    rm -rf "@{CI_PROJECT_DIR}"
    mkdir -p "@{CI_PROJECT_DIR}"
    chown 1000:1000 -R "@{CI_PROJECT_DIR}"
    if [[ -d "/cache/git-v3/@{CI_PROJECT_PATH}/@CI_CONCURRENT_ID" ]]; then
      trap 'rm -rf "/cache/git-v3/@{CI_PROJECT_PATH}/@CI_CONCURRENT_ID"' ERR
      # Concurrent jobs are separated into different git repo cache folders
      echo "Copying the git repo from /cache/git-v3/@{CI_PROJECT_PATH}/@{CI_CONCURRENT_ID} to @{CI_PROJECT_DIR}"
      /usr/bin/time cp -a --no-target-directory "/cache/git-v3/@{CI_PROJECT_PATH}/@CI_CONCURRENT_ID/" "@{CI_PROJECT_DIR}/"

      if [[ -n "@{GIT_CLONE_PATH:-}" && "@{GIT_CLONE_PATH:-}" != "@{CI_PROJECT_DIR}" ]]; then
        # @GIT_CLONE_PATH is set to a value different from @{CI_PROJECT_DIR}
        # In general the two should be the same so this code path should never be exercised
        rm -rf "@GIT_CLONE_PATH"
        mkdir -p "@GIT_CLONE_PATH"
        chown 1000:1000 -R "@GIT_CLONE_PATH"
        /usr/bin/time cp -a --no-target-directory "/cache/git-v3/@{CI_PROJECT_PATH}/@CI_CONCURRENT_ID/" "@GIT_CLONE_PATH/"
      fi


      # Ensure the git repo is clean and up to date with the upstream
      cd "@{CI_PROJECT_DIR}"
      git reflog expire --expire=now --all
      git gc --prune=now
      git fsck --full
      git submodule foreach git reflog expire --expire=now --all
      git submodule foreach git gc --prune=now
      git submodule foreach git fsck --full
      # Disable all background git operations
      git config gc.auto 0
      git config gc.autodetach false

      # Ensure that there are not background git operations running and remove all lock files if they exist
      if ! {
        set -e
        pkill git || true
        find .git -name '*.lock' -delete
        # Delete all branches for which a reference (sha) does not exist
        set +x
        git for-each-ref --format="%(refname)" | while read ref; do
          git show-ref --quiet --verify @ref 2>/dev/null || git update-ref -d @ref
        done
        set -x
        if ! git remote add origin "@{CI_REPOSITORY_URL}"; then
          git remote set-url origin "@{CI_REPOSITORY_URL}"
        fi
        git fetch --prune --prune-tags
        # Run a GC on the repo
        git gc --prune=now --force
        git reflog expire --expire=0 --all
      }; then
        rm -rf .git
      fi
    fi
    echo -e "\e[0Ksection_end:$(date +%s):pre_clone_script\r\e[0K"

before_script:
  - |
    # Execute the before_script section

    # Start the (collapsed) before_script section
    set -exuo pipefail
    echo -e "\e[0Ksection_start:$(date +%s):before_script[collapsed=true]\r\e[0KClick here to see the before_script section"

    mkdir -m 0700 -p ~/.ssh
    echo -e "Host *\nUser gitlab-runner\n" > ~/.ssh/config
    ulimit -n 8192
    date

    # forget original timestamp/timestamp when compressing ~ important for reproducibility
    export GZIP=-n

    # alpine image don't have  git nor rsync
    if [[ -n "$(which apk)" ]]; then
      apk add rsync sudo git
    fi

    if ! id -u ubuntu > /dev/null 2>&1; then
      mkdir -p "/home/ubuntu"
      echo "ubuntu:x:99:99:ubuntu:/home/ubuntu:/bin/sh" >> /etc/passwd
      echo "ubuntu:x:99:" >> /etc/group
      chown ubuntu:ubuntu -R "/home/ubuntu"
    fi

    # Set the IC repo URL to https instead of ssh, and check out the submodule
    sudo chown ubuntu:ubuntu -R .  
    git submodule set-url ic "https://github.com/dfinity/ic.git"
    if ! git submodule update --init --recursive --remote; then
      cat .git/config
      cat .gitmodules
      cat .git/modules/ic/config
      rm -rf /cache/git-v3/${CI_PROJECT_PATH}
      exit 1
    fi

    sudo chown ubuntu:ubuntu -R "${CI_PROJECT_DIR}"
    sudo find "${CI_PROJECT_DIR}" -type d -exec chmod 0755 '{}' \;
    # Update the git repo cache at /cache/git-v3/${CI_PROJECT_PATH}/$CI_CONCURRENT_ID
    sudo mkdir -p "/cache/git-v3/${CI_PROJECT_PATH}/$CI_CONCURRENT_ID/"
    sudo chown ubuntu:ubuntu -R "/cache/git-v3/${CI_PROJECT_PATH}/$CI_CONCURRENT_ID/"
    /usr/bin/time rsync -a --force --delete "$CI_PROJECT_DIR"/ "/cache/git-v3/${CI_PROJECT_PATH}/$CI_CONCURRENT_ID/"

    cd "${CI_PROJECT_DIR}"
    # Ensure file permissions in the repo are what git expects them to be
    git config core.fileMode true
    git reset --hard HEAD

    echo -e "\e[0Ksection_end:$(date +%s):before_script\r\e[0K"

    # Setup SSH keys
    if [[ -z "$(which ssh-agent)" ]]; then 
      if [[ -n "$(which apk)" ]]; then
        apk add openssh-client
      elif [[ -n "$(which apt-get)" ]]; then 
        apt-get update -y && apt-get install openssh-client -y
      else  
        echo "- ERROR system has neither apk nor apt-get"
        echo "  Could not install ssh-agent"
        exit 1
      fi
    fi

    eval $(ssh-agent -s)
    cat "$DASHBOARD_DEPLOY_KEY" | tr -d '\r' | ssh-add -

.rules-default:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run

.rules-autorun-on-trigger:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'

docker-image-update:
  stage: .pre
  extends:
    - .rules-default
  interruptible: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - docker/**/*
        - Pipfile
        - Pipfile.lock
        - pyproject.toml
        - poetry.lock
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
  script:
    - python3 docker/docker-update-image.py

pre-commit:
  extends:
    - .rules-default
  interruptible: true
  needs: []
  dependencies: []
  stage: test
  variables:
    PRE_COMMIT_HOME: "/cache/pre-commit/${CI_PROJECT_PATH}/$CI_CONCURRENT_ID"
  script:
    - pre-commit install
    - pre-commit run -a --hook-stage=manual

cargo-clippy:
  extends:
    - .rules-default
  interruptible: true
  needs: []
  dependencies: []
  stage: test
  script:
    - cd rs
    - ./cargo-clippy

cargo-test:
  extends:
    - .rules-default
  interruptible: true
  needs: []
  dependencies: []
  stage: test
  script:
    - cd rs
    - cargo test

valid-inventory:
  extends:
    - .rules-default
  interruptible: true
  needs: []
  dependencies: []
  stage: test
  script:
    - |
      set -exou pipefail  # Don't tolerate any errors
      set +x

      for depl in mainnet mercury staging; do
          if [[ "$depl" == "mainnet" ]]; then ARGS="--decentralized-deployment"; else ARGS=""; fi
          echo "************************************************************"
          echo "Listing Ansible inventory for: $depl"
          echo "************************************************************"
          ./deployments/env/$depl/hosts $ARGS --list > $depl-hosts-list.json
          head $depl-hosts-list.json
          echo "<contents trimmed>"
          echo "word count [wc $depl-hosts-list.json]: $(wc $depl-hosts-list.json)"

          echo "************************************************************"
          echo "Listing nodes for: $depl"
          echo "************************************************************"
          ./deployments/env/$depl/hosts $ARGS --nodes

          echo "************************************************************"
          echo "Listing NNS nodes for: $depl"
          echo "************************************************************"
          ./deployments/env/$depl/hosts $ARGS --nns-nodes
      done
      for depl in dev prod; do
          echo "************************************************************"
          echo "Listing Boundary Nodes Ansible inventory for: $depl"
          echo "************************************************************"
          ./deployments/boundary-nodes/env/$depl/hosts --list > $depl-hosts-list.json
          head $depl-hosts-list.json
          echo "<contents trimmed>"
          echo "word count [wc $depl-hosts-list.json]: $(wc $depl-hosts-list.json)"

          echo "************************************************************"
          echo "Listing Boundary Nodes for: $depl"
          echo "************************************************************"
          ./deployments/boundary-nodes/env/$depl/hosts --nodes
      done

update-facts-db:
  interruptible: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "update-factsdb"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
  script:
    - |
      set -exou pipefail  # Don't tolerate any errors
      # Work on main branch
      git config pull.rebase true
      git config --global user.name "Release Team"
      git config --global user.email "eng-release-bots-aaaafbmaump5gpag4pbjfuarry@dfinity.slack.com"
      time git pull --depth 5 --force origin "${CI_DEFAULT_BRANCH}"
      git checkout --force "${CI_DEFAULT_BRANCH}"

      set +x
      time python3 ./factsdb/main.py --refresh
      time python3 ./factsdb/main.py --deployment-name mainnet --decentralized-deployment --refresh
      if [[ -n "$(git status --short factsdb/data)" ]]; then
        echo "Changed files found";
        git add factsdb/data
        git stash
        git pull --rebase
        git stash pop
        git add factsdb/data
        git status
        git commit -m"Updated FactsDB"
        git remote set-url origin "https://token:${GITLAB_PUSH_TOKEN}@${CI_REPOSITORY_URL#*@}"
        git push origin "${CI_DEFAULT_BRANCH}"
      fi

jira-update:
  interruptible: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "update-jira-tickets"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
  script:
    - |
      set -exou pipefail  # Don't tolerate any errors

      cd ./scripts/jira-integration
      time python3 ./jira_update.py

qualification-tracking-update:
  interruptible: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "update-qualification-tracking"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
  script:
    - |
      set -exou pipefail  # Don't tolerate any errors

      cd ./qualification
      time python3 ./qualification_track.py add-nns
      time python3 ./qualification_track.py add-ci --since=now-3d

update-ic-versions-file:
  interruptible: true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "update-ic-versions"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
  script:
    - |
      set -exou pipefail  # Don't tolerate any errors

      time python3 ./scripts/ic_versions/main.py

      if [[ -z "$(cd ic; git log -1 | grep 'Update Mainnet IC revisions file')" ]]; then
          # No commit was made by the automation, we can stop here
          exit 0
      fi

      # Assign the MR reviewer and merge the MR once approved
      MR_NUM=$(curl --fail --request GET --header "PRIVATE-TOKEN: $IC_CREATE_VERSIONS_MR_TOKEN" "https://gitlab.com/api/v4/projects/31166135/merge_requests/?state=opened&source_branch=ic-mainnet-revisions" | jq '.[].iid')
      if [[ -n "$MR_NUM" ]]; then
          # Assign the reviewer to DSD https://gitlab.com/danielstefan.dietiker
          curl --fail --request PUT --header "PRIVATE-TOKEN: $IC_CREATE_VERSIONS_MR_TOKEN" "https://gitlab.com/api/v4/projects/31166135/merge_requests/$MR_NUM?reviewer_ids[]=7781103"
      fi
      sleep 10 # Wait to let GitLab update the MR metadata
      if [[ "$(curl --fail --request GET --header "PRIVATE-TOKEN: $IC_CREATE_VERSIONS_MR_TOKEN" "https://gitlab.com/api/v4/projects/31166135/merge_requests/$MR_NUM/approval_state" | jq '[.rules[].approved] | all')" == "true" ]]; then
          # The MR has all necessary approvals
          # ==> merge as soon as possible
          curl --fail --request PUT --header "PRIVATE-TOKEN: $IC_CREATE_VERSIONS_MR_TOKEN" "https://gitlab.com/api/v4/projects/31166135/merge_requests/$MR_NUM/merge?merge_when_pipeline_succeeds=true&squash=true"
      fi

.docker-base:
  image: docker/compose:alpine-1.29.2
  needs: []
  dependencies: []
  stage: release
  retry: 2
  interruptible: true
  before_script:
    - docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" $CI_REGISTRY
  variables:
    RELEASE_BRANCH: release
    COMPOSE_DOCKER_CLI_BUILD: "1"
    DOCKER_BUILDKIT: "1"


dashboard-release-build:
  extends:
    - .docker-base
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - changes:
        - dashboard/**/*
        - rs/**/*
  script:
    - | 
      set -exou pipefail

      cd dashboard
      TAG=latest

      # pull latest layer to help with build times
      docker-compose pull || true
      TAG=lastest docker-compose -f docker-compose.yml -f docker-compose.dev.yml build --parallel

dashboard-release-publish:
  extends:
    - .docker-base
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      changes:
        - dashboard/**/*
        - rs/**/*
  script:
    - | 
      set -exou pipefail

      cd dashboard

      # pull latest layer to help with build times
      docker-compose pull || true
      TAG=latest docker-compose -f docker-compose.yml -f docker-compose.dev.yml build --parallel
      TAG=latest docker-compose -f docker-compose.yml -f docker-compose.dev.yml push
      TAG=${CI_COMMIT_SHA} docker-compose -f docker-compose.yml -f docker-compose.dev.yml build --parallel
      TAG=${CI_COMMIT_SHA} docker-compose -f docker-compose.yml -f docker-compose.dev.yml push
      
      # checkout branch
      apk add git 
      git clone "https://gitlab-ci-token:${GITLAB_API_TOKEN}@gitlab.com/dfinity-lab/private/k8s/k8s.git"

      cd k8s
      git config user.email "idx@dfinity.org"
      git config user.name "IDX GitLab Automation"
      git checkout -b "update-image-tag-${CI_COMMIT_SHA}"

      # sed the changes
      # this regex matches the first group (ie the image name) and uses \1
      # called a back-reference to insert the first group matched, the second
      # part is to match the 40 characters hash that we replace with the $CI_COMMIT_SHA
      sed -i "s~\(\([[:alpha:]]\|-\)\+\):[[:alnum:]]\{40\}~\1:${CI_COMMIT_SHA}~g" bases/apps/mainnet-dashboard/statefulset-slack.yaml bases/apps/mainnet-dashboard/backend/base/deployment.yaml bases/apps/mainnet-dashboard/frontend/deployment.yaml

      # commit, push & create new merge request
      git add .
      if git diff --cached --quiet; then
          echo "No changes to commit."
          exit 0
      fi

      git commit -m "Updating container base image refs"
      git push \
          -o merge_request.create \
          -o merge_request.title="[nomrbot] - Updating container image refs mainnet-dashboard [$CI_COMMIT_SHA]" \
          -o merge_request.description="Changes to the release repository - [here](https://gitlab.com/dfinity-lab/core/release/-/commit/$CI_COMMIT_SHA)" \
          --force --set-upstream origin "update-image-tag-${CI_COMMIT_SHA}"

qualify-release:
  timeout: 2h
  resource_group: staging # Eliminate concurrent test runs
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_NAME == "qualify-release"'
      # Run the job automatically if the QUALIFY_GIT_REVISION env var is provided in the web UI when the pipeline was created
    - if: '$CI_PIPELINE_SOURCE == "web" && $QUALIFY_GIT_REVISION != ""'
    - if: '$CI_PIPELINE_SOURCE == "trigger"'
      when: manual
      allow_failure: true # the pipeline continues running even if the manual job is not run
  script:
    - |
      set -exou pipefail  # Don't tolerate any errors

      mkdir -p /home/ubuntu/.config/dfx/identity/bootstrap-super-leader
      cat "$BOOTSTRAP_SUPER_LEADER_PEM" > /home/ubuntu/.config/dfx/identity/bootstrap-super-leader/identity.pem
      mkdir -p /home/ubuntu/.config/dfx/identity/xnet-testing
      cat "$XNET_TESTING_PEM" > /home/ubuntu/.config/dfx/identity/xnet-testing/identity.pem
    - ./qualification/qualify-new-release.py --git-revision ${QUALIFY_GIT_REVISION}

metrics-proxy-release:
  stage: release
  extends:
    - .rules-default
  interruptible: true
  before_script:
    - docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" $CI_REGISTRY
  variables:
    IMAGE_REGISTRY_BASE: $CI_REGISTRY_IMAGE
    RELEASE_BRANCH: release
    DOCKER_BUILDKIT: "1"
    IMAGE_TAG: "vector-up-proxy:latest"
  script:
    - cd metrics-proxy
    - docker build -t "$IMAGE_REGISTRY_BASE/$IMAGE_TAG" .
    - if [ "${CI_COMMIT_BRANCH}" != "${CI_DEFAULT_BRANCH}" ]; then exit 0; fi
    - docker push $IMAGE_REGISTRY_BASE/$IMAGE_TAG

linear-jira-release:
  stage: release
  extends:
    - .rules-default
  interruptible: true
  before_script:
    - docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" $CI_REGISTRY
  variables:
    IMAGE_REGISTRY_BASE: $CI_REGISTRY_IMAGE
    DOCKER_BUILDKIT: "1"
    IMAGE_NAME: "$IMAGE_REGISTRY_BASE/linear-jira"
  script:
    - cd linear-jira
    - docker build -t "$IMAGE_NAME:latest" .
    - if [ "${CI_COMMIT_BRANCH}" != "${CI_DEFAULT_BRANCH}" ]; then exit 0; fi
    - docker tag "$IMAGE_NAME:latest" "$IMAGE_NAME:$CI_COMMIT_SHA"
    - docker push "$IMAGE_NAME:$CI_COMMIT_SHA"
    - docker push "$IMAGE_NAME:latest"
