#!/usr/bin/env python3

"""
Plot per-subnet failure-rate time series from node metrics CSVs.

Inputs:
- One or more CSV files generated by the node rewards CLI, typically named
  `node_metrics_by_day.csv` or `node_metrics_by_node.csv` located under provider
  directories.

What it does:
- Concatenates the provided CSVs
- Filters to rows where nodes are Assigned to a subnet
- Classifies generations:
  - gen1: node_reward_type in {type0, type1, type1.1}
  - gen2: all other types
- For each subnet, produces a single PNG with 3 subplots:
  1) Median failure rate by generation (relative_fr), legend lists node prefixes colored by generation
  2) Daily node counts by generation (stacked)
  3) Original failure rates for all nodes with original_fr > 0.2 (scatter), colored by generation

Usage examples:
  python scripts/plot_subnet_failure_rates.py \
    --input /path/to/rewards_*/**/node_metrics_by_day.csv \
    --output ./subnet_plots

  python scripts/plot_subnet_failure_rates.py \
    --input /Users/me/dre2/rs/cli/rewards_14-08-2025_to_12-09-2025/**/node_metrics_by_node.csv \
    --output ./subnet_plots

Requires: pandas, matplotlib
  pip install pandas matplotlib
"""

import argparse
import glob
import os
from typing import List, Tuple

import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import pandas as pd


GEN1_TYPES = {"type0", "type1", "type1.1"}


def read_csvs(paths: List[str]) -> pd.DataFrame:
    """Read and concatenate CSVs. Accepts file paths and glob patterns."""
    expanded_paths: List[str] = []
    for p in paths:
        # Expand both wildcards and directories
        if os.path.isdir(p):
            # Search for both known filenames recursively
            expanded_paths.extend(glob.glob(os.path.join(p, "**", "node_metrics_by_day.csv"), recursive=True))
            expanded_paths.extend(glob.glob(os.path.join(p, "**", "node_metrics_by_node.csv"), recursive=True))
        else:
            expanded_paths.extend(glob.glob(p))

    if not expanded_paths:
        raise SystemExit("No CSV files found. Provide file paths, directories, or glob patterns.")

    usecols = [
        "day_utc",
        "node_id",
        "node_reward_type",
        "node_status",
        "subnet_assigned",
        "relative_fr",
        "original_fr",
    ]

    frames: List[pd.DataFrame] = []
    for path in expanded_paths:
        try:
            df = pd.read_csv(path, usecols=usecols)
        except ValueError:
            # Some files may have slightly different column order/names; read all then select if present
            df = pd.read_csv(path)
            missing = [c for c in usecols if c not in df.columns]
            if missing:
                # Skip files that clearly are not node_metrics files
                continue
            df = df[usecols]
        df["__source_file"] = path
        frames.append(df)

    if not frames:
        raise SystemExit("No valid node_metrics CSVs found after scanning inputs.")

    all_df = pd.concat(frames, ignore_index=True)

    # Normalize types
    # Day format is like 14-08-2025; parse with dayfirst=True
    all_df["day_utc"] = pd.to_datetime(all_df["day_utc"], dayfirst=True, errors="coerce")
    # Ensure numeric failure rate; invalid becomes NaN
    all_df["relative_fr"] = pd.to_numeric(all_df["relative_fr"], errors="coerce")
    all_df["original_fr"] = pd.to_numeric(all_df["original_fr"], errors="coerce")
    # original_fr not required when plotting medians
    # Keep only Assigned with a subnet value
    all_df = all_df[(all_df["node_status"] == "Assigned") & (all_df["subnet_assigned"].notna()) & (all_df["subnet_assigned"] != "")]

    # Classify generation
    all_df["generation"] = all_df["node_reward_type"].apply(lambda t: "gen1" if str(t) in GEN1_TYPES else "gen2")

    # Drop rows missing day or subnet after cleaning
    all_df = all_df.dropna(subset=["day_utc", "subnet_assigned"]).copy()

    return all_df


def compute_series(df: pd.DataFrame, subnet: str) -> Tuple[pd.Series, pd.Series, pd.Series, pd.Series, pd.Series]:
    """Compute daily mean/median failure rates and counts by generation for a subnet.

    Returns:
      mean_gen1, mean_gen2, median_gen1, median_gen2, counts_gen1 (gen2 can be derived similarly)
    """
    sub = df[df["subnet_assigned"] == subnet].copy()

    # Mean per day per generation
    mean = sub.groupby(["day_utc", "generation"])['relative_fr'].mean().unstack("generation")
    median = sub.groupby(["day_utc", "generation"])['relative_fr'].median().unstack("generation")

    # Counts of unique nodes per day per generation
    counts = sub.groupby(["day_utc", "generation"])['node_id'].nunique().unstack("generation")

    for frame in (mean, median, counts):
        if frame is not None:
            if "gen1" not in frame.columns:
                frame["gen1"] = 0 if frame is counts else float("nan")
            if "gen2" not in frame.columns:
                frame["gen2"] = 0 if frame is counts else float("nan")
            frame.sort_index(inplace=True)

    return (
        mean.get("gen1"),
        mean.get("gen2"),
        median.get("gen1"),
        median.get("gen2"),
        counts.get("gen1"),
    )


def add_stats_box(ax: plt.Axes, label: str, series: pd.Series, yoffset: float = 0.0) -> None:
    """Add mean/std text block to the provided axes for a series."""
    if series is None or series.dropna().empty:
        return
    s = series.dropna()
    text = f"Statistics for {label}:\n  Mean: {s.mean():.6f}\n  Standard Deviation: {s.std():.6f}"
    ax.text(
        0.01,
        0.02 + yoffset,
        text,
        transform=ax.transAxes,
        fontsize=9,
        family="monospace",
        verticalalignment="bottom",
        bbox=dict(boxstyle="round,pad=0.3", facecolor="#f7f7f7", edgecolor="#cccccc"),
    )


def plot_subnet(df: pd.DataFrame, subnet: str, out_dir: str) -> None:
    # For counts stacked bar, compute both gen1 and gen2 counts
    sub = df[df["subnet_assigned"] == subnet].copy()
    counts = sub.groupby(["day_utc", "generation"])['node_id'].nunique().unstack("generation").fillna(0).astype(int)
    for col in ("gen1", "gen2"):
        if col not in counts.columns:
            counts[col] = 0
    counts = counts.sort_index()

    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(14, 13), sharex=True)

    # 1) Median failure rates by generation (lines), legend lists node prefixes colored by gen
    mean_g1, mean_g2, med_g1, med_g2, _ = compute_series(df, subnet)
    if med_g1 is not None:
        ax1.plot(med_g1.index, med_g1.values, label="gen1", color="#1f77b4", marker="o", linestyle="-")
    if med_g2 is not None:
        ax1.plot(med_g2.index, med_g2.values, label="gen2", color="#ff7f0e", marker="x", linestyle="-")
    ax1.set_title(f"Median Failure Rates by Generation (Subnet: {subnet})")
    ax1.set_ylabel("Failure Rate (relative_fr)")
    ax1.grid(True, linewidth=0.4, alpha=0.5)

    # Build legend entries with node prefixes, colored by their generation
    prefix_gen = (
        sub.assign(prefix=sub["node_id"].astype(str).apply(lambda s: s.split('-')[0]))
        .drop_duplicates(subset=["prefix", "generation"])[["prefix", "generation"]]
        .sort_values("prefix")
    )
    handles = []
    labels = []
    for _, row in prefix_gen.iterrows():
        color = "#1f77b4" if row["generation"] == "gen1" else "#ff7f0e"
        h = plt.Line2D([], [], color=color, marker="o", linestyle="", markersize=6)
        handles.append(h)
        labels.append(row["prefix"])
    if handles:
        ax1.legend(handles, labels, title="Node prefix (color=gen)", ncol=2, fontsize=8, framealpha=0.9)

    # 2) Node counts stacked bars by generation
    x = counts.index
    ax2.bar(x, counts["gen1"], label="gen1", color="#1f77b4")
    ax2.bar(x, counts["gen2"], bottom=counts["gen1"], label="gen2", color="#ff7f0e")
    ax2.set_title(f"Node Counts by Generation (Subnet: {subnet})")
    ax2.set_ylabel("Count")
    ax2.legend(title="Generation")
    ax2.grid(True, axis="y", linewidth=0.4, alpha=0.5)

    # Annotate total node counts on top of stacked bars
    totals = (counts["gen1"] + counts["gen2"]).astype(int)
    gen1_counts = counts["gen1"].astype(int)
    gen2_counts = counts["gen2"].astype(int)
    if not totals.empty:
        ymax = totals.max()
        # Ensure headroom for labels
        ax2.set_ylim(top=max(ax2.get_ylim()[1], float(ymax) * 1.15 + 1))
        y_offset = max(1.0, float(ymax) * 0.02)
        for xi, total in zip(x, totals):
            ax2.text(
                xi,
                float(total) + y_offset * 0.2,
                f"{int(total)}",
                ha="center",
                va="bottom",
                fontsize=8,
            )
        # Also label gen1 segment inside the blue bar
        for xi, g1 in zip(x, gen1_counts):
            if g1 > 0:
                ax2.text(
                    xi,
                    float(g1) / 2.0,
                    f"{int(g1)}",
                    ha="center",
                    va="center",
                    fontsize=8,
                    color="white",
                )
        # Label gen2 segment inside the orange bar
        for xi, g1, g2 in zip(x, gen1_counts, gen2_counts):
            if g2 > 0:
                ax2.text(
                    xi,
                    float(g1) + float(g2) / 2.0,
                    f"{int(g2)}",
                    ha="center",
                    va="center",
                    fontsize=8,
                    color="white",
                )

    # 3) Scatter of original_fr for all nodes with original_fr > 0.2, colored by generation
    high = sub[(sub["original_fr"].notna()) & (sub["original_fr"] > 0.2)].copy()
    if not high.empty:
        for gen, color, label in (("gen1", "#1f77b4", "gen1"), ("gen2", "#ff7f0e", "gen2")):
            df_g = high[high["generation"] == gen]
            if not df_g.empty:
                ax3.scatter(
                    df_g["day_utc"],
                    df_g["original_fr"],
                    s=12,
                    alpha=0.6,
                    color=color,
                    label=label,
                )
    ax3.set_title(f"Original Failure Rates > 0.2 by Generation (Subnet: {subnet})")
    ax3.set_ylabel("Failure Rate (original_fr)")
    ax3.grid(True, linewidth=0.4, alpha=0.5)
    ax3.legend(title="Generation")

    # Shared x formatting
    ax3.set_xlabel("Day")
    ax3.xaxis.set_major_locator(mdates.AutoDateLocator())
    ax3.xaxis.set_major_formatter(mdates.ConciseDateFormatter(ax3.xaxis.get_major_locator()))
    fig.autofmt_xdate()

    fig.tight_layout()

    os.makedirs(out_dir, exist_ok=True)
    safe_subnet = subnet.replace(os.sep, "_")
    outfile = os.path.join(out_dir, f"{safe_subnet}_failure_rates.png")
    fig.savefig(outfile, dpi=150)
    plt.close(fig)
    print(f"Saved plot: {outfile}")


def main() -> None:
    parser = argparse.ArgumentParser(description="Plot per-subnet failure rates by generation from node metrics CSVs")
    parser.add_argument(
        "--input",
        "-i",
        nargs="+",
        required=True,
        help="CSV file paths, directories, or glob patterns (e.g., path/**/node_metrics_by_day.csv)",
    )
    parser.add_argument(
        "--output",
        "-o",
        required=True,
        help="Output directory for PNG plots",
    )
    args = parser.parse_args()

    df = read_csvs(args.input)

    subnets = sorted(df["subnet_assigned"].dropna().unique())
    if not subnets:
        raise SystemExit("No assigned subnets found in the input CSVs.")

    for subnet in subnets:
        plot_subnet(df, subnet, args.output)


if __name__ == "__main__":
    main()


